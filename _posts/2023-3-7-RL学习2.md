---
title: RL学习随记
key: 2023-3-7-2
tags: 
- 强化学习
- 
modify_date: 2023-3-7
author: 徐文江
show_author_profile: true
---

# 免模型控制        

把策略迭代进行广义的推广，使它能够兼容蒙特卡洛和时序差分的方法，即带有蒙特卡洛方法和时序差分方法的**广义策略迭代（generalized policy iteration，GPI）**        

策略迭代由两个步骤组成。第一，我们根据给定的当前策略 *π* 来估计价值函数；第二，得到估计的价值函数后，我们通过贪心的方法来改进策略           

![策略迭代](https://datawhalechina.github.io/easy-rl/img/ch3/model_free_control_1.png)      



