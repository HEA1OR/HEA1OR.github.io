---
title: 大语言模型(LLM)是否终结了自然语言处理(NLP)领域
key: 2023-9-26-1
tags: 
- NLP
- 大模型
- 深度学习
modify_date: 2023-9-26
author: 徐文江
show_author_profile: true
---

## 原视频[地址](https://www.bilibili.com/video/BV1ew411i7KZ/)         
<!--more-->  


自从ChatGPT问世以来   
很多人都在担忧自己会不会被AI   
抢了饭碗   
但你有没有想过   
他给人工智能从业者带来的冲击   
当然   
距离强人工智能的出现还有一段距离   
但以GPT为代表的大语言模型的出现   
是否意味着人工智能领域中   
研究语言理解生成的那部分   
也就是自然语言处理领域   
已经被彻底终结了   
就拿我自己来说   
我读博时候的研究室   
就是自然语言处理研究室   
当时被我们研究室奉为圣经   
每周都要轮读的这本书   
实事求是的讲   
咱就从纯工程角度考虑   
现在还有多少内容是真正有价值的   
关于自然语言处理还要不要学   
能不能做之类的问题   
在知乎上也是一搜一大把   
就在上个月   
本领域的大佬级人物Dan Klein   
在西蒙斯研究所做了主题演讲   
对这个问题给出了他的看法   
自然语言处理的历史可以追溯到上   
世纪50年代   
也就是说在人工智能发展的黎明期   
人们就已经开始思考   
如何让机器理解自然语言的问题   
起初人们认为   
可以通过一阶   
逻辑或者   
类似的统一系统来实现人工智能   
但最后发现   
追求用一致的方法解决   
所有问题的结果   
就是要么无法深入解决现实问题   
要么规则彼此之间开始产生冲突   
所以开始将领域不断细分   
NLP和CV处理问   
题的方式当然不一样   
但就算是在NLP内部   
也有分词语法解析语义解析   
实体识别指代消解等   
各式各样的子领域   
每个子领域又都有自己关心的问题   
独有的表述方式以及各式各样的算法   
但NLP的目标   
或者说广义上AI的长期目标是什么   
终究是追求知识的泛化性与通用性   
也就是说   
我从一个数据源学习到的知识   
要能用它来处理别处的某个问题才行   
那我们能从自然语言的数据源   
也就是语料库中学到什么呢   
我们能学到单词的向量表   
记和语义上的层级结构   
知道great   
good和enjoyable在语义上离得很近   
dog   
和is则是完全不同方向上的东西   
然后呢   
这些知识的确能用在其他地方   
但在相当长一段时期   
它能发挥的作用非常有限   
直到像Elmo   
和Bert   
这样的中型预训练语言模型的出现   
NLP才进入了一个更加横向的阶段   
也就是说无论你下游任务做什么   
都可以拿预训练模型当做起点   
再接下来   
就进入到了大语言模型的时代   
像GPT和T5   
人们开始用一个模型执行多项任务   
可能在某些任务上不如专项模型   
但已经开始显现出了通用性   
这个时候   
很多搞NLP的人都陷入了恐慌   
认为NLP的问题已经解决了   
我还能做什么   
要不回家种地去吧   
而Dan认为其实还有很多事情要做   
并正式点题   
大语言模型   
究竟是NLP的起始还是终结   
他给出的答案是是   
起始阶段的终结   
也就是说曾经需要拿语言本身做文章   
以语言本身作为研究对象的那个时代   
已经过去了   
但还存在三个大方向可以做   
一是垂直任务转向水平技术栈的问题   
二是模块化与单体化的问题   
三是安全与真相问题   
我们先来看垂直转水平的问题   
如刚才所说   
以前在这个领域   
可以垂直分解为很多子领域   
现在大语言模型来了   
只要你的表达到位   
这些任务他全都可以做   
但我们来看看这张协议栈的图   
它是先有物理层   
才有上面的数据链路层网络层   
直到最顶的应用层   
这些层相互依赖   
每层都不能孤立的解决问题   
所以Dan在这里预测   
我们从今往后将进入到一个新世界   
也就是从纵向分割   
转为横向的分层技术栈的世界   
在这个新世界   
大语言模型将扮演非常重要的角色   
但也要和其他层相互配合才行   
至于其他层是什么现在还很难讲   
不过Dan给了几个例子   
比如说   
你现在想用chatGPT写一篇长篇小说   
给一个开头   
一个年轻女子决心一辈子不嫁人   
结果她遇到了心目中的完美男人   
于是她重新审视自己的决定   
你让GPT根据这个开头续写   
写是能写   
但结果肯定不理想   
大概率会出现前后信息不一致   
中途改变风格之类一系列的问题   
所以你需要一个额外的控制层   
或者说超结构   
来引导和增强大语言模型   
限制他的输出   
让他始终在一个轨道上运作   
比如你可以先写一些设   
定角色或大纲   
然后分层次写草稿   
这样每部分都不会太大   
而且过程中人类也可以插手   
进行某种交互或协作   
这和单纯依靠语言模型相比   
在连贯性和相关性上都会更好   
另一个例子比如填字游戏   
里边当然用到了大语言模型   
但同时也包含了搜索技术   
而且这个应用在美国的顶级锦标赛中   
已经击败了人类选手   
如果你只是把填字游戏转成JSON格式   
然后让GPT填   
它肯定填不了这么好   
所以在大语言模型基础上   
混合其他技术或模块   
可以在专业任务上   
取得比单独使用语言模型更好的性能   
第二点是模块化与单体化的问题   
我们在计算机科学课程里学到的是   
要把项目模块化   
把问题分解成更小的碎片   
做到层次分明   
只有这样在某个层出现问题时   
你才能知道发生了什么   
并可以迅速定位到问题所在   
而你在机器学习课程里学到的东西   
就像一个香肠制造机   
里边构造什么的全都不知道   
就外边给你露几个旋钮用来配置   
其他所有设计   
都是不透明的   
现在有了大语言模型   
我们确实可以在外部微调   
亦或进行所谓的提示工程   
但始终欠缺计算机科学所   
需要的透明度   
如果有可能将其模块化是不是会更好   
Dan在这里就举了个模块化的例子NMN   
也就是神经模块化网络   
假设神经网络是一个大型可编程电路   
现在你有一个计算机视觉问题   
问狗在哪   
你用CNN来识别狗用语法   
解析器来解析出where   
配合LSTM得到沙发的答案   
还可以根据不同问题组成不同的回路   
实现不同的行为   
再举一个例子   
这个叫CodeVQA   
比如问马车在马的右边吗   
系统会先用计算机   
视觉识别出马的存在   
并分别获取   
马和马车在二维平面的坐标   
再通过自编程的手段来判断   
最终得到准确答案   
看到这里我猜很多观众会提多模态   
我可以非常负责任的说   
GPT的多模态架构以及运作方式   
跟Dan举的这两个例子完全是两码事   
GPT的多模态能不能解决类似问题   
根据年初openAI的技术演示当然能   
而且可能效果会非常好   
但作为非确定性模型   
它的泛化性和精度   
究竟能够到达什么程度   
还要等到明年真正开放使用后   
才能见分晓   
第三点是安全与真相问题   
大语言模型的幻觉问题固然是缺陷   
但哪怕能够正常输出   
也有可能会造成危害   
近一年来   
你可以看到各类教育工作者的文章   
关于多少多少学生用chatGPT抄袭作弊   
又有多少多少学校禁用chatGPT   
这里Dan介绍了一个他们开发的系统   
Ghostbuster喂他一段文本   
他就能检测出是不是来自大语言模型   
在实际表现上也比其他检测器   
比如detectGPT和GPT Zero要好   
这算是提供了一种解决   
AI生成内容潜在滥用的工具   
还有一点就是   
大语言模型的优化目标   
究竟应该如何设定   
只需要让用户满意就可以吗   
Dan在这里举了个蛮有意思的思想实验   
假如你让一个客服机器人   
按照用户满意度进行强化学习训练   
结果会怎样呢   
结果会是明明不会退款   
但他会告诉用户肯定给退款   
又或者货明明明天都不会到   
但他会告诉用户货今天下午就到   
用户听了肯定会开心   
但这些都不符合事实   
可你按照用户的实时   
满意度来进行优化的话   
结果就会导致   
模型做出偏离真相的行为   
此外当一个系统能够完成多个任务   
我们一般会认为这是好事   
但系统一旦遭到攻击   
很可能意味着这个系统在   
全部任务上的表现   
都会被毒化   
多任务模型潜在的脆弱性   
也是不得不考虑的安全性问题   
总的来说   
Dan认为大语言模型的出现意味着   
NLP旧时代的终结   
但仍面临很多实际应用中的难题   
有待解决   
也就是刚才提到的三个方向   
垂直问题转化为水平问题   
模块与单体之间的协调问题   
安全性和控制等问题   
以上就是演讲的全部内容   
最后谈谈我的个人看法   
事实上   
Dan提到的这些大语言模型的问题   
也是openAi在近段时间努力解决的问题   
比如插件机制代码解释器   
安全方面的问题就更不用说了   
现在还可以说我们有这些事要做   
这些事我们要在新时代解决的问题   
可如果下一代或下两代GPT   
用各种途径解决了这些问题   
我们又该何去何从   
我的看法是   
尽量避开这些openAI正在解决   
或快要解决的问题   
去做一些大语言模型   
在本质上就难以取得突破   
的问题   
比如我之前   
介绍过的杨立昆的一些思路   
亦或去做一些   
openAI受商业利益考量不会去做的事情   
比如模型的小型化和本地化   
又或者   
可以在符号主义与连接主义结合方面   
做一些新的尝试   
其实这几点也是我个人比较感兴趣   
并正在努力的几个方向   
那本期内容就到这里   
感谢收看我们下期再见 