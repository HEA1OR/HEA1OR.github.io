---
title: 快速搞懂神经网络中的Tensor（张量）是什么？有什么用？
key: 2023-9-30-1
tags: 
- 深度学习
- Tenser
- 数学
modify_date: 2023-9-30
author: 徐文江
show_author_profile: true
---

## 原视频[地址](https://www.youtube.com/watch?v=L35fFDpwIM4)         
<!--more--> 

张量为数据做这件事   
张量是为了速度   
张紧器在你觉得需要的时候做   
你好   
我是乔希·斯托默，欢迎收看今天的统计探索   
我们将讨论神经网络的张量   
他们会被清楚地解释   
让张量有点困惑的一件事   
不同的人使用张量这个词的方式不同   
数学和物理学界的人们用一种方式定义张量   
机器学习社区的人们以不同的方式定义张量   
在这个堆栈任务中   
我们将关注张量在机器学习社区中的使用方式   
在机器学习社区中   
张量与神经网络结合使用   
所以我们无论如何都需要谈谈神经网络   
神经网络可以做很多事情   
例如   
在堆栈任务中   
黑匣子里的神经网络第一部分   
我们有一个简单的神经网络，有一个单一的输入药物剂量   
并使用单个值来预测单个输出   
叠加探索中剂量对反向传播的影响   
我们看到即使有这个超级简单的神经网络和这个超级简单的训练数据   
只有三个数据点   
我们还得为神经网络做很多数学计算   
为了将这个曲线与数据拟合   
堆栈任务神经网络第四部分多输入输出   
我们有一个更漂亮的神经网络   
它有两个输入，对应于两个不同的花测量   
并有三个输出，预测了这两个测量来自哪个爱尔兰物种   
然后我们看到神经网络是如何做很多数学的   
做出那些预测   
堆栈中的探索神经网络第八部分图像分类   
用卷积神经网络   
我们有一个超级花哨的神经网络   
它有一个6像素乘6像素的图像   
所以总共三个六个像素作为输入   
两个输出预测图像是x还是o   
我们做了很多我们需要做的数学题   
为了让这些预测翻三倍，呃，这么多数学   
即使这个神经网络需要做大量的数学运算   
还是比较简单的   
与实践中使用的神经网络类型相比   
例如   
这个卷积神经网络的输入相对较小   
6像素乘6像素   
黑白图像   
但是   
在实践中   
通常输入图像要大得多   
像二百五十六乘二百五十六   
这意味着输入有六万五千   
536像素   
通常图像是彩色的而不是黑白的   
彩色图像通常被分成三个颜色通道   
红色   
绿色和蓝色   
因为神经网络分别处理每个通道   
这基本上是我们要计算的像素数的三倍   
所以现在我们有三次   
六十   
五千   
五百三十六   
等于一百   
九十   
六千   
六百八个像素，我们要做很多数学运算   
这只是一张照片   
通常我们需要做大量的图像来训练神经网络   
所以这意味着我们必须对大量的图像进行大量的数学运算   
如果我们想把神经网络应用于视频   
基本上是一系列的图像   
然后我们有更多的数学   
好消息是所有这些数学都是张量设计的目的   
巴姆   
现在呢   
让我们来谈谈什么是张量   
从创建神经网络的人的角度来看   
张量是存储输入数据的方法   
哪个   
在本例中   
由每一帧的三个颜色通道组成   
但正如我们之前看到的   
输入也可以是超级简单的，由单个值组成   
和张量   
还要存储组成神经网络的权重和偏差   
从某人创建神经网络的角度来看   
张量看起来真的很无聊   
一个都没有   
例如   
这个神经网络的输入值只是一个值   
在大多数编程语言中我们称之为标量   
但是   
为了让事情看起来更刺激   
我们可以使用花哨的术语，调用输入，它只是一个单一的值   
当神经网络接受两个像这样的输入值时的零维张量   
在大多数编程语言中   
我们可以说我们将输入存储在一个数组中   
但是   
使用张量谈话   
我们称之为一维张量   
同样地   
当输入是单个图像时   
大多数编程语言都称之为矩阵   
但我们称之为二维张量   
当输入是视频时   
大多数编程语言称之为多维矩阵或多维数组   
或为你   
Python   
人与ND阵列   
但是   
使用张量谈话   
我们称之为n维张量   
就像我之前说的   
从某人创建神经网络的角度来看   
张量看起来真的很无聊   
因为我们所做的只是重新命名已经存在的东西   
有什么大不了的   
嗯   
与正常标量不同   
数组   
矩阵与n维矩阵   
张量的设计是为了利用硬件加速   
换句话说   
张量不只是以这样的各种形状保存数据   
但它们也考虑到了我们必须处理的所有数学问题   
要相对较快完成的数据   
通常   
张量   
他们所做的数学运算被称为图形处理单元的特殊芯片加速   
Gpus   
但也有张量处理单元   
Tpus   
专门设计来处理张量并使神经网络运行相对较快   
我很早就暗示过一件事   
但没有深入探讨   
那就是   
我们用神经网络做的一件事是   
用反向传播估计最优权重和偏差   
如果你看过关于反向传播的堆栈任务   
你就会知道我们得推导出一系列的导数   
做了很多链式法则   
嗯   
张量的另一个很酷的地方是，它们处理了反向传播   
为您提供自动差异化   
这意味着你几乎可以创建有史以来最奇特的神经网络   
最难的是弄清楚   
导数将由张量三重ba照顾   
总之   
有两种类型的张量   
一种是数学家和物理学家使用的   
我们今天没有谈这些   
另一种张量用于神经网络   
这就是我们谈到的神经网络张量的类型   
保存数据和权重和偏见   
是为硬件加速而设计的   
所以神经网络可以做所有的数学   
他们需要在相对较短的时间内   
它们用自动分化来处理反向传播   
Bam   