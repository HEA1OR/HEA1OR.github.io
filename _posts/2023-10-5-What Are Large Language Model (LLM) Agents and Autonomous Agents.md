---
title: What Are Large Language Model (LLM) Agents and Autonomous Agents
key: 2023-10-5-1
tags: 
- 深度学习
- LLM
- 数学
modify_date: 2023-10-5
author: 徐文江
show_author_profile: true
---

## 原文[地址](https://www.promptengineering.org/what-are-large-language-model-llm-agents/)         
### LLM agents是大模型下一步发展方向，更是我即将读研的核心方向，最近找了很多相关文章，不过读的似懂非懂。这篇文章是刷到知乎的一篇读后简记的原文，感觉很有意思，就翻译了一下。原文有点长，我也挑重点简记了一下，有兴趣的可以去看原文。    
<!--more--> 

GPT-4等大型语言模型（LLM）在生成类人文本方面表现出了令人印象深刻的能力。最近的研究超越了文本生成，将LLM构建为代理和自治代理的核心控制器，这些代理不仅可以写作，还可以推理、行动和学习。     
       
LLM具有作为人工通用智能系统发挥作用的潜力。它们正迅速从被动语言系统转变为<font color="#ffff00">主动的、面向目标的、能够自主推理和完成任务的代理</font>。        
        
#### 这一发展标志着人工智能领域的一次巨大转变，并有望彻底改变人类与机器的交互方式。          

什么是大型语言模型（LLM）代理
LLM代理是一种人工智能系统，它利用大型语言模型（LLM）作为其核心计算引擎来展示文本生成以外的功能，包括进行对话、完成任务、推理，并可以演示某种程度的自主行为。

LLM代理通过精心设计的提示进行指导，这些提示对角色、指令、权限和上下文进行编码，以形成代理的响应和操作。

LLM代理的一个关键优势是他们具有不同程度的自治能力。基于设计阶段授予的能力，代理可以表现出从纯粹被动到高度主动的自我导向行为。

有了足够的提示和知识访问，LLM代理可以半自动地工作，在一系列应用程序中帮助人类，从对话聊天机器人到工作流和任务的目标驱动自动化。

它们的灵活性和语言建模优势为可定制的人工智能合作伙伴提供了新的可能性，这些合作伙伴能够理解自然语言提示并与人类监督协作。

为了提高自主能力，LLM代理需要访问知识库、内存和推理工具。即时工程使代理具备分析、项目规划、执行、回顾过去工作、迭代优化等方面的高级技能。有了足够的知识和提示，代理可以在人工监督下管理相对独立的工作流。

这最终通过将角色、指令和权限编码为精心编制的提示来指导代理的行为。用户通过提供交互式提示来响应人工智能的输出，从而有效地引导代理。精心设计的提示允许无缝的人机协作。


典型结构LLM代理
LLM代理的关键功能
LLM代理利用LLM固有的语言能力来理解指令、上下文和目标。这使他们能够根据人类的提示自主和半自主地操作。
LLM代理可以利用一系列工具（计算器、API、搜索引擎）来收集信息并采取行动完成分配的任务。它们不仅仅局限于语言处理。
LLM代理可以展示思想链推理、思想树和其他及时的工程概念，建立逻辑连接以得出结论并解决问题。他们的推理超越了文本理解。
LLM代理可以通过将上下文和目标融入他们的语言制作技能，为特定目的生成定制的文本——电子邮件、报告、营销材料。
代理可以是完全自主的或半自主的，需要不同级别的用户交互。
代理可以耦合不同的AI系统，例如大型语言模型和图像生成器，以实现多方面的功能。
从LLM到代理的演变——快速回顾
大型语言模型（LLM）最初是被动系统，只专注于统计语言建模。像GPT-2这样的早期LLM可以生成或总结令人印象深刻的文本，但缺乏任何目标、身份或代理的概念。他们是没有行动动机的榜样。

随着时间的推移，用户意识到仔细的即时工程可以从LLM中引发更多人性化的响应。人物角色和身份被编码到提示中，以塑造LLM的语气、观点和知识。更先进的提示技术允许LLM计划、反映和展示基本推理。


这促使了基于LLM的代理的兴起，这些代理旨在模拟对话或实现定义的任务。像ChatGPT这样的对话代理采用人物角色来进行非常人性化的对话。面向目标的代理将LLM的推理能力集中到执行工作流上。

随着快速工程实践的成熟，这两种类型的代理都受益匪浅。即时配方使预定义的结构得以优化，以实现一致性和效率。模块化组件和元素允许更大程度的定制。

为代理配备外部存储器、知识集成和工具集成大大扩展了其功能。多代理协作进一步释放了新的潜力。在这一切的基础上，迭代提示工程仍然是指导代理行为的关键。

如今，被动LLM和交互式、半自主代理之间的界限已大大模糊。代理展现出令人印象深刻的代理能力，利用他们的LLM在提示下协作，而不仅仅是回应。随着快速工程从LLM那里获得了越来越先进的推理、学习和技能，这一演变仍在迅速进行。

提示周期概述
迭代提示周期是促进用户和LLM代理之间自然对话的关键：

用户提示：用户提供启动对话的初始提示，并将代理指向特定任务或讨论主题。
即时工程：提示符的创建经过精心设计，以向LLM提供最佳指令和上下文。语气、观点和谈话风格等因素有助于引导LLM的反应。
LLM生成：LLM在其当前上下文窗口中处理编码的提示，以生成相关的文本响应。响应显示了细微差别，反映了及时的工程。
LLM自回归链：LLM生成的文本递归添加到上下文窗口中。这使得LLM能够建立在自己的响应之上，以自回归方式链接输出。
用户反馈回路：用户提供后续提示以响应LLM的输出。此反馈通过循环的进一步迭代引导对话。
上下文扩展：在每个循环中，上下文窗口都会扩展，从而允许LLM代理积累知识并更好地理解用户的会话目标。
重复骑行：在许多周期中，LLM代理集中于解决方案，揭示更深入的见解，并在不断发展的对话中保持主题焦点。

当代LLM提示周期
提示工程框架的循环特性允许用户以交互式、动态的方式高效地指导LLM代理。每次迭代都会进一步训练代理，使其与用户的需求保持一致。

什么是好的AI提示？
人工智能提示符是一段精心编制的文本或其他输入，提供给人工智能系统以引发期望的响应。人工智能提示是将用户的意图传达给底层机器学习模型的指令。


提示的结构和内容对于成功指导人工智能系统至关重要。提示的设计必须与所利用的特定AI模型的功能相一致。不同的人工智能模型被训练成专门处理特定类型的输入和输出。

当提示生成性人工智能系统（如大型语言模型和图像生成模型）时，用户必须提供描述性文本以指示所需的输出。提示符中的措辞和详细程度会显著影响人工智能响应的质量和相关性。

本质上，人工智能提示以人工智能可以处理和处理的自然语言编码用户的请求。即时工程是将想法转化为优化指令的技能，从而产生准确、相关和有用的人工智能输出。有效的提示将人工智能系统视为一个协作伙伴，用户通过交互式提示小心地指导机器的行为。

人工智能提示的剖析
人工智能提示由几个基本构建块组成，它们共同为人工智能系统提供指令和上下文。了解有效提示的核心组件有助于用户精心设计优化的提示。

任务：任务定义了人工智能的预期输出或目标。这可以是回答问题、生成图像或生成创造性内容。明确说明任务有助于聚焦人工智能系统。

说明：指令为AI提供了如何执行任务的具体指示。这包括输出的所需属性、格式、内容要求和任何约束。指令作为指导人工智能的规则。

上下文：Context提供定位任务的背景信息。示例、图像和其他种子为AI模型提供了预期响应的感觉。语境起着灵活的指导作用，而不是坚定的规则。

参数：参数是改变AI处理提示方式的配置。这包括诸如温度和top-p之类的设置，这些设置会影响输出的创造性和随机性。

输入数据：对于图像编辑等任务，提示符必须包含AI转换的输入数据。语言模型也需要文本输入。

仔细组合这些核心组件，使用户能够高效地提示AI系统。任务和指令提供了方向，而上下文和数据则为AI提供了所需的参考。参数微调最终输出。培养快速解剖学专业知识是快速工程的关键。

提示组件中的元素
上述AI提示的关键组件可以进一步分解为更精细的元素。每个组件都包含许多元素，有助于为AI系统提供一套完整详细的指令和上下文。

例如，Task组件包含以下元素：

角色-人工智能应采用的角色
命令-指导AI的动作动词
主题-主题重点领域
查询-要回答的特定问题
“说明”组件元素包括：

输出-生成内容的预期属性
结构-组织格式、节、流
应做事项-可接受的质量和内容
不可接受的品质和内容
要点/想法-要包括的具体概念
示例-用于说明所需输出的示例
Context组件包含以下元素：

目标受众-内容的目标消费者
视角-要采用的观点
目的-目标和动机
补充信息-其他背景详细信息
Parameters组件包含如下设置：

温度-创造力/不可预测性水平
长度-生成的内容大小
Top-p-不太可能输出的可能性
惩罚-抑制不必要的输出
模型-使用的AI系统
通过将提示分解为更精细的元素，用户可以精确地为AI系统定制指令，并实现对输出的更大控制。元素级提示工程解锁增强的提示功能。

提示食谱
提示配方是以结构化格式构建AI提示的预定义模板。它们提供了一个框架，将任务、指令、上下文和参数的核心组件组合成可重用的模式。

即时食谱的主要优点是标准化。通过填写配方模板，用户可以快速生成新的提示，并在各个用例中保持一致。这确保了人工智能系统结果的可靠性和一致性。


在每个配方中，某些字段预先填充了默认设置，而其他字段保持打开状态以进行自定义。这样，用户可以根据自己的具体需要定制提示，同时保持整个配方结构。可定制的字段可能包括特定的内容要求、目标受众、期望的音调、输出长度、创造力水平等。

共享和协作编辑配方有助于通过迭代和测试进行优化。可以对配方进行编目和性能跟踪，以确定最佳模板。将配方分组到项目中可以围绕业务域和用例进行组织。

随着时间的推移，用户可以构建涵盖各种场景和应用程序的广泛提示配方库。新的配方可以建立在现有配方的基础上，作为知识化合物。维护结构化配方允许用户自适应地结合各种技术，以推动AI提示可实现的范围。

大型语言模型代理的结构
那么，构建这些代理到底需要什么呢？将原始语言模型转换为功能强大的自治代理需要小心地将核心LLM与用于知识、内存、接口和工具的其他组件集成。

虽然LLM是基础，但创建能够理解指令、展示有用技能并与人类协作的代理需要三个关键要素：底层LLM架构本身、有效的即时工程和代理的接口。


让我们探讨一下将LLM从被动文本生成器升级为主动、半自主代理的核心组件。了解代理创建所涉及的要素可以发现部署这些AI系统以获得真实世界帮助的机会和注意事项。我们将详细介绍如何将LLM转换为LLM代理。

LLM核心
LLM代理的基础是底层的大型语言模型本身。该神经网络基于大量数据集进行训练，提供基本的文本生成和理解能力。LLM的大小和体系结构决定了代理的基线能力和限制。

提示配方
同样重要的是有效的即时配方，以激活和指导LLM的技能。精心设计的提示为代理人提供了其角色、知识、行为和目标。提示配方提供了预定义的模板，结合了关键指令、上下文和参数，以一致地引发所需的代理响应。

提示中嵌入的人物角色对于会话代理采用独特的说话风格至关重要。对于以任务为导向的代理，提示会分解目标，提供相关知识，并给出框架说明。

界面和交互
该界面确定用户如何向代理提供提示。命令行、图形或对话界面允许不同级别的交互。完全自主的代理可以通过API以编程方式从其他系统或代理接收提示。

界面会影响代理交互是否感觉像是前后协作，而不是自我指导的助手。平滑的界面将重点放在提示本身上。

存储器
内存提供时间上下文，并记录特定于单个用户或任务的详细信息。代理中通常使用两种形式的内存：

短期内存-LLM的固有上下文窗口保持对最近对话历史或最近采取的行动的认识。
长期记忆-一个与LLM配对的外部数据库，用于扩展过去对事实、对话和其他相关细节的回忆能力。长期内存为代理配备了持久的累积内存库。
内存为代理提供了时间和用户特定体验方面的基础。此上下文使对话个性化，并提高多步骤任务的一致性。

知识
记忆侧重于暂时的用户和任务细节，而知识则代表适用于所有用户的一般专业知识。知识扩展了LLM本身在其模型参数中包含的内容。

专业知识-用针对特定主题或领域的特定领域词汇、概念和推理方法补充LLM的基础。
常识性知识-补充了LLM可能缺乏的一般世界知识，如社会、文化、物理等方面的事实。
程序知识-提供完成任务的专业知识，如工作流、分析技术和创造性流程。
注入知识可以扩展代理可以理解和讨论的内容。即使记忆在任务中被重置或调整，知识仍然是相关的。这种组合使知识渊博的代理能够拥有个性化的记忆。

将内存和知识实现分开可以最大限度地提高配置代理以满足不同需求的灵活性。代理可以将不同的知识源与随时间积累的用户特定内存存储集成。

*保持记忆与知识的逻辑分离
为LLM代理实现单独的外部内存和知识存储提供了许多好处，包括：

能够分析代理的推理技能如何随着时间的推移而演变，因为它的内存在积累，而其知识保持不变。比较随时间变化的输出可以隔离扩展内存的影响。
允许有选择地“刷新”代理的内存，而不会丢失一般知识。这对于进行新项目很有用，因为之前的背景记忆可能会带来偏见。擦除内存，同时保留知识，使代理严格关注新的任务上下文。
通过错误提示或数据注入，保护代理的审查知识库免受潜在恶意内存修改的影响。独立的商店保持可信赖的知识的原始性。
总的来说，当LLM代理处理不同的任务并构建纵向经验时，将外部内存与注入的知识分离可以提高LLM代理行为的灵活性、可解释性和安全性。体系结构分离使两个组件的效用最大化。

工具集成
代理不需要仅通过语言生成来执行操作，工具集成允许通过API和外部服务来完成任务。例如，代理可以使用代码执行工具来运行提示符中引用的软件例程，或“插件”，如OpenAi的代码解释器。

总之，LLM代理将强大的核心能力与补充组件集成在一起，以展示其令人印象深刻的能力。底层的LLM提供基本的语言技能，而即时配方则将这些能力导向目标和人物角色。界面可以实现交互，额外的记忆和知识可以提高对上下文的理解。

总之，这些成分使协作、半自主的代理人能够理解自然语言、推理提示、积累记忆并采取知情行动。LLM代理已经超越了被动语言建模，成为了能够帮助人类跨越大量对话和任务导向领域的合作伙伴。

然而，它们的性能和一致性最终取决于它们收到的提示的质量。深思熟虑的即时工程仍然是在LLM过渡到能力越来越强的代理时，从LLM释放更大智能和效用的关键驱动因素。

LLM代理的两种主要类型
大型语言模型使新一代人工智能代理具备了令人印象深刻的功能。这些基于LLM的代理可以根据其主要功能分为两种关键类型：会话代理和面向任务的代理。

虽然两者都利用了语言模型的力量，但这两种代理类型在目标、行为和激励方法上有着重要的区别。

对话代理专注于提供富有吸引力的个性化讨论，而任务型代理则致力于完成明确定义的目标。

在下面的部分中，我们将探讨每种类型的LLM代理所特有的特征和提示注意事项。了解差异可以让用户根据自己的需要选择和指导合适的代理。

1.会话代理：模拟人类对话
自然语言处理的最新进展使人工智能系统（如ChatGPT和GPT-4）具有卓越的会话能力。这些对话主体可以进行令人印象深刻的类人对话，理解上下文并用现实的陈述作出回应。

会话代理，例如合成交互式角色代理（SIPA）呈现提示所定义的个性，这些提示描述了他们的语气、说话风格、观点和领域知识。这允许用户与拟人代理交互时进行细微的讨论。

合成交互式角色代理（SIPA）
克服使用合成交互式人格代理寻找研究参与者的挑战。

即时工程
 苏尼尔·拉姆洛坎

对话主体的一个主要吸引力在于他们在讨论中反映人类倾向的能力。当通过即时工程制定时，代理会考虑诸如语气、说话风格、领域知识、观点和个性怪癖等因素。这允许微妙的上下文交互。

在诸如客户服务聊天机器人之类的应用程序中，对话代理可以利用人物角色提示来形成让人感到自然和有同情心的响应。他们在语言理解和生成方面的能力使对话感觉流畅和适应性强。

会话代理也为以交互方式收集反映人类讨论的信息打开了大门。他们可以通过提示采用领域专业知识，担任知情顾问或专家，例如在医疗或法律领域。

会话代理提供者继续增强记忆、知识集成和响应质量能力。随着时间的推移，这些人工智能系统可能有足够的能力通过扩展的图灵测试，并作为功能齐全的虚拟助理。

由语言模型支持的会话代理标志着人机交互的重大发展。他们能够通过及时的工程设计参与富有成效的个性化对话，这为许多行业和应用程序带来了新的可能性。

2.面向任务的代理：目标驱动的生产力
与会话代理相反，例如生成性人工智能网络（GAIN），以任务为导向的人工智能代理直接关注实现既定目标和完成工作流。这些目标驱动的系统擅长将高级任务分解为更易于管理的子任务。

生成性人工智能网络（GAIN）
GAIN是一种快速工程技术，用于解决单个代理能力之外的复杂挑战。

即时工程
 苏尼尔·拉姆洛坎

面向任务的代理利用其强大的语言建模功能来分析提示、提取关键参数、制定计划、调用API、通过集成工具执行操作，并报告结果。这样可以自动处理多方面的目标。

即时工程使以任务为导向的代理具备重新制定战略任务、链接思想路线、反思过去工作以及迭代改进方法的技能。当代解决问题的技巧也可以编码为提示，以加强分析和规划。

有了足够的知识和工具，以任务为导向的代理可以在即时定义的目标的驱动下半自主地工作。他们的工作可以由人类合作者异步审查。

面向任务的代理组还可以通过集中的提示界面进行协调。这使得AI代理团队能够相互补充，以实现广泛的目标。代理处理不同的子任务，同时团结一致地朝着总体目标努力。

未来，企业级任务自动化和增强将越来越多地利用以目标为中心的代理。他们的专业提示使代理不仅能够理解自然语言提示，而且能够根据这些提示采取行动，以推动进步和生产力。

是什么使LLM代理自治？
对于LLM代理来说，要表现出有意义的自主性，它不能仅仅孤立地响应单个提示，它必须在一个持续的过程中不断地被引导。这就提出了一个问题：是什么提供了这种持续的激励来实现自治行为？

当前LLM的一个关键限制是，它们不能独立地执行递归自循环来递归地提示自己。LLM在没有外部干预的情况下，无法固有地质疑其自身的输出和自我表现。

真正的自主性需要一个外部系统来审查代理人的回应，必要时提供指导和纠正，并根据上下文提供后续提示。这个自动提示系统充当管理者，负责管理代理的持续学习和改进。

在大多数情况下，该监管系统是另一个AI代理，通常是LLM本身。两个代理同时工作-一个生成响应，另一个根据需要审查和重新推荐第一个代理。多智能体交互创建了发展自主技能的训练循环。

主管代理检查生成的代理的工作，提供后续提示和说明，并提供交互式反馈。这种通过API介导的耦合提示关系，支撑了生成的代理从狭义能力向一般智力的发展。

从本质上讲，自主性是由激励生态系统中的代理之间的相互作用产生的。通过专门的主管代理提供指导、纠正和增加挑战的持续提示，培养自主技能。持续不断的激励开启了推理、有效性和自我导向决心的增长。

基于代理的方法的优点
使用人工智能系统作为由语言模型提供动力的交互式、半自主代理提供了一系列优势：

安全-代理可以通过安全的API进行容器化和连接，以限制风险。他们的互动受到监控和审查。
模块化-可以根据需要组装和协调具有不同功能的代理。添加或交换代理非常简单。
灵活性-代理角色和行为通过提示进行指导，允许动态配置。
自动化-与更严格的人工智能系统相比，代理需要更少的持续人工监督。
专业化-代理可以基于集中的激励策略在特定领域建立深入的专业知识。
质量-监控代理对话可以不断改进提示，以提高准确性和相关性。
隐私-当代理操作衍生品时，敏感用户数据可以保持分区。
总的来说，基于代理的范式在人类控制和人工智能自主之间提供了一个最佳点。代理与人工提示协作，通过迭代进行改进。将AI助手构建为目标驱动的代理可以带来许多好处。

外卖
大型语言模型正迅速从被动文本生成器演变为多功能、半自主和自治的代理。谨慎的即时工程从LLM核心激活对话和任务驱动能力。知识库、工具集成和内存等辅助组件使代理能够演示扩展的推理和专业知识。

对话代理可以通过个性化对话和特定领域的建议吸引用户。面向任务的代理将其技能集中到执行工作流和目标上。LLM代理经过适当的架构，提供了灵活的智能，可以跨大量应用程序与人类协作。

然而，他们的最终潜力仍然与他们收到的提示的质量有关。发展即时工程的艺术和科学是安全高效地指导这些系统的关键。随着提示的改进，LLM代理的能力也将提高，从而开启人工智能辅助的新领域。
