---
title: 深入GPU原理
key: 2023-4-18-1
tags: 
- GPU
- 机器学习
modify_date: 2023-4-18
author: 徐文江
show_author_profile: true
---

[视频链接](https://www.bilibili.com/video/BV1bm4y1m7Ki/)            
GPU设计目标是最大化吞吐量，更关心并行度（parallelisim），即同时可以执行多少任务         
CPU则更关心延迟和并发（concurrency）        
<!--more-->     

----------------------

并行：能够同时处理多个任务          
并发：能够处理多个任务的功能               

---------------------------

GPU时延比CPU高，但线程远远多于CPU           
CPU希望一个线程里可以完成所有的工作，重心在减少延迟           


----------------
GPU缓存机制         
高带宽内存HBM Memory                 
caches缓存包括多级：L2 Cache Shared Mem Per SM，L1 Cache Shared across all SMs，Register File per SM            
GPU直接计算数据时延会很高，所以需要HBM      


---------------

GPU线程机制           
Streaming Multiprosessor（SM）看作基本运算单元，每个SM中有64个warps           
每四个warp进行一个并发执行，通过增加warp掩盖延迟的问题           

--------------------
很多时候线程不被用完。            